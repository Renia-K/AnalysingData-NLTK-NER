## AnalysingData NLTK & NER

## Natural Language Processing

This project involves a series of NLP tasks applied to a dataset of five texts, utilizing the NLTK and spaCy libraries in Python.

**PART I**

For this part we conducted: 

`Sentence segmentation and word tokenization`

`Word frequency analysis`

`Visualization of the 25 most common words`

`Stemming using Porter and Lancaster stemmers`

`Comparison of stemmed vs. unstemmed results`

`POS tagging for Tom Sawyer translations (NL-EN-DE)`

`POS tag frequency analysis`


**Part II**

For this part we conducted: 

`Named Entity Recognition (NER)`

`Manual annotation of two sentences per story`

`Performance evaluation of automatic NER compared to manual annotation`

## Creators
This dataset was created and curated by Theodora-Stavroula Korma on behalf of the course Analyzing Data, for the MA Digital Humanities. 

**Contact Information**:
email: t.s.korma@student.rug.nl

## Usage
This dataset is provided for educational purposes, intended to support the final individual assignment for the course **Analyzing Data**, of 2a semester of MA Digital Humanities. 
